{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venky0112/Stock-Market-Price-Prediction/blob/main/Hybrid_Model_For_Forecasting_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39e6172",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c39e6172",
        "outputId": "9d565462-7706-4d22-8c21-b29f88bcc311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pmdarima\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting joblib>=0.11 (from pmdarima)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 49, in _iter_built\n",
            "    for version, func in infos:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 300, in iter_index_candidate_infos\n",
            "    result = self._finder.find_best_candidate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 884, in find_best_candidate\n",
            "    candidates = self.find_all_candidates(project_name)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 825, in find_all_candidates\n",
            "    page_candidates = list(page_candidates_it)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/sources.py\", line 194, in page_candidates\n",
            "    yield from self._candidates_from_page(self._link)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 792, in process_project_url\n",
            "    package_links = self.evaluate_links(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 772, in evaluate_links\n",
            "    candidate = self.get_install_candidate(link_evaluator, link)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 752, in get_install_candidate\n",
            "    self._log_skipped_link(link, result, detail)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 740, in _log_skipped_link\n",
            "    logger.debug(\"Skipping link: %s: %s\", detail, link)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 73, in emit\n",
            "    if self.shouldRollover(record):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 191, in shouldRollover\n",
            "    if os.path.exists(self.baseFilename) and not os.path.isfile(self.baseFilename):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen genericpath>\", line 19, in exists\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1632, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1601, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 360, in __init__\n",
            "    self.process = os.getpid()\n",
            "                   ^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m567.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, numpy, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 numpy-2.1.3 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'statsmodels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e8d6df1156ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_acf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade --force-reinstall pmdarima\n",
        "!pip install python-dotenv\n",
        "!pip install statsmodels\n",
        "!pip install tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_pacf,plot_acf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from pmdarima import auto_arima # This line should now work without errors\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "load_dotenv()\n",
        "Filename_address = os.getenv(\"FILE_ADDRESS\")\n",
        "Output_address = os.getenv(\"OUTPUT_ADDRESS\")\n",
        "close = \"Adj_Close\"\n",
        "lag = os.getenv(\"LAG\")\n",
        "epochs = int(os.getenv(\"EPOCHS\"))\n",
        "learning_rate = float(os.getenv(\"LEARNING_RATE\"))\n",
        "batch_size = int(os.getenv(\"BATCH_SIZE\"))\n",
        "number_nodes = int(os.getenv(\"NUMBER_NODES\"))\n",
        "days = int(os.getenv(\"Prediction_days\"))\n",
        "n = int(os.getenv(\"NN_LAGS\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0c54b7",
      "metadata": {
        "id": "eb0c54b7"
      },
      "source": [
        "Basically loading the data and making a data-frame wrt to time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb2e577",
      "metadata": {
        "id": "acb2e577"
      },
      "outputs": [],
      "source": [
        "def data_loader():\n",
        "   cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj_Close\", \"Volume\"]\n",
        "   data = pd.read_csv(Filename_address, index_col=\"Date\", parse_dates=True)\n",
        "   data.columns = cols\n",
        "   data = data.dropna()\n",
        "   print(f\"The Shape of the Data-Set is : {data.shape}\\nThe Data-Set is : \\n{data.head()}\\n\")\n",
        "   return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a24fc906",
      "metadata": {
        "id": "a24fc906"
      },
      "source": [
        "Plotting Line Graph with data and column name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b52873",
      "metadata": {
        "id": "75b52873"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train, predictions,title):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(train.index, train, label='Actual')\n",
        "    plt.plot(train.index, predictions, label='Predicted', color='red')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Close-Price')\n",
        "    address = Output_address + title + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_raw_data(data):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(data.index, data[close], label='Close Price')\n",
        "    plt.title('Raw Time Series Data')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.legend()\n",
        "    address = Output_address + 'Raw Time Series Data' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_train_test(train, test):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(train.index, train, label='Train Set')\n",
        "    plt.plot(test.index, test, label='Test Set', color='orange')\n",
        "    plt.title('Train and Test Data')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Close Price')\n",
        "    address = Output_address + 'Train and Test Data' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_prediction_errors(errors):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(errors, label='Prediction Errors')\n",
        "    plt.title('Prediction Errors over Time')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Error')\n",
        "    plt.legend()\n",
        "    address = Output_address + 'Prediction Errors over Time' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_final_predictions(test, final_predictions):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(test.index, test, label='Actual')\n",
        "    plt.plot(test.index, final_predictions, label='Corrected Prediction', color='green')\n",
        "    plt.title('Final Predictions with Error Correction')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.legend()\n",
        "    address = Output_address + 'Final Predictions with Error Correction' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_accuracy(mse, rmse, mae):\n",
        "    metrics = ['MSE', 'RMSE', 'MAE']\n",
        "    values = [mse, rmse, mae]\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(metrics, values, color=['blue', 'orange', 'green'])\n",
        "    plt.title('Model Accuracy Metrics')\n",
        "    address = Output_address + 'Model Accuracy Metrics' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n",
        "def plot_arima_accuracy(mse, rmse, mae):\n",
        "    metrics = ['MSE', 'RMSE', 'MAE']\n",
        "    values = [mse, rmse, mae]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(metrics, values, color=['blue', 'orange', 'green'])\n",
        "    plt.title('ARIMA Model Accuracy Metrics')\n",
        "    address = Output_address + 'Model Accuracy Metrics' + \".jpg\"\n",
        "    plt.savefig(address)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f89b5d",
      "metadata": {
        "id": "f0f89b5d"
      },
      "source": [
        "Data Partination For my model development and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf464d1c",
      "metadata": {
        "id": "bf464d1c"
      },
      "outputs": [],
      "source": [
        "def data_allocation(data):\n",
        "   train_len_val = len(data) - days\n",
        "   train,test = data[close].iloc[0:train_len_val],data[close].iloc[train_len_val:]\n",
        "   print(\"\\n--------------------------------- The Training Set is : -------------------------------------------\\n\")\n",
        "   print(train)\n",
        "   print(f\"\\nThe Number of Enteries : {len(train)}\\n\")\n",
        "   print(\"\\n--------------------------------- The Testing Set is : --------------------------------------------\\n\")\n",
        "   print(test)\n",
        "   print(f\"\\nThe Number of Enteries : {len(test)}\\n\")\n",
        "   return train,test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fa1bbd",
      "metadata": {
        "id": "08fa1bbd"
      },
      "source": [
        "Here we are Transforming the data for the Neural Network in a lag based matrix (nth:matrix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a36bd5",
      "metadata": {
        "id": "47a36bd5"
      },
      "outputs": [],
      "source": [
        "def apply_transform(data, n: int):\n",
        "    middle_data = []\n",
        "    target_data = []\n",
        "    for i in range(n, len(data)):\n",
        "        input_sequence = data[i-n:i]\n",
        "        middle_data.append(input_sequence)\n",
        "        target_data.append(data[i])\n",
        "    middle_data = np.array(middle_data).reshape((len(middle_data), n, 1))\n",
        "    target_data = np.array(target_data)\n",
        "    return middle_data,target_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "290dcf85",
      "metadata": {
        "id": "290dcf85"
      },
      "source": [
        "This the LSTM model training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5c384cc",
      "metadata": {
        "id": "b5c384cc"
      },
      "outputs": [],
      "source": [
        "def LSTM(train,n : int, number_nodes, learning_rate, epochs, batch_size):\n",
        "   middle_data, target_data = apply_transform(train, n)\n",
        "   model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input((n,1)),\n",
        "      tf.keras.layers.LSTM(number_nodes,input_shape=(n, 1)),\n",
        "      tf.keras.layers.Dense(units = number_nodes,activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(units = number_nodes,activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(1)\n",
        "   ])\n",
        "   model.compile(loss = 'mse',optimizer = tf.keras.optimizers.Adam(learning_rate),metrics = [\"mean_absolute_error\"])\n",
        "   print(f\"middle_data shape: {middle_data.shape}\")\n",
        "   print(f\"target_data shape: {target_data.shape}\")\n",
        "   print(f\"LSTM input shape: {model.layers[0].input_shape}\")\n",
        "   history = model.fit(middle_data,target_data,epochs = epochs,batch_size = batch_size,verbose = 0)\n",
        "   full_predictions = model.predict(middle_data).flatten()\n",
        "   return model,history,full_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f435408",
      "metadata": {
        "id": "4f435408"
      },
      "source": [
        "Calculating Accuracy of the Both the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9415c58d",
      "metadata": {
        "id": "9415c58d"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(true_values, predictions):\n",
        "    mse = mean_squared_error(true_values, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(true_values, predictions)\n",
        "    return mse,rmse,mae\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b2d5b71",
      "metadata": {
        "id": "6b2d5b71"
      },
      "source": [
        "Error Evaluation from the Prediction made from LSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92c2c6b",
      "metadata": {
        "id": "d92c2c6b"
      },
      "outputs": [],
      "source": [
        "def Error_Evaluation(train_data,predict_train_data,n:int):\n",
        "   errors = []\n",
        "   for i in range(len(predict_train_data)):\n",
        "      err = train_data[n + i] - predict_train_data[i]\n",
        "      errors.append(err)\n",
        "   return errors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9295ee",
      "metadata": {
        "id": "5e9295ee"
      },
      "source": [
        "ARIMA Parameter Selection and PACF & ACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c1d5a1",
      "metadata": {
        "id": "71c1d5a1"
      },
      "outputs": [],
      "source": [
        "def Parameter_calculation(data):\n",
        "   finding = auto_arima(data,trace = True)\n",
        "   plot_acf(data,lags = lag)\n",
        "   address = Output_address + \"ACF\" +\".jpg\"\n",
        "   plt.savefig(address)\n",
        "   plot_pacf(data,lags = lag)\n",
        "   address = Output_address + \"PACF\" +\".jpg\"\n",
        "   plt.savefig(address)\n",
        "   ord = finding.order\n",
        "   return ord\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5388eb",
      "metadata": {
        "id": "ed5388eb"
      },
      "source": [
        "ARIMA Model Function for Predicting the possible ERRORS from LSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0331a369",
      "metadata": {
        "id": "0331a369"
      },
      "outputs": [],
      "source": [
        "def ARIMA_Model(train,len_test,ord):\n",
        "   model = ARIMA(train, order = ord)\n",
        "   model = model.fit()\n",
        "   predictions = model.predict(start = len(train),end = len(train) + len_test ,type='levels')\n",
        "   full_predictions = model.predict(start = 0,end = len(train)-1,type='levels')\n",
        "   return model,predictions,full_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49dbe2c6",
      "metadata": {
        "id": "49dbe2c6"
      },
      "source": [
        "The Final Prediction : LSTM predicted value + ARIMA predicted Error value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b692541f",
      "metadata": {
        "id": "b692541f"
      },
      "outputs": [],
      "source": [
        "def Final_Predictions(predictions_errors,predictions):\n",
        "   final_values = []\n",
        "   for i in range(days):\n",
        "      final_values.append(predictions_errors[i] + predictions[i])\n",
        "   return final_values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19b0b4a",
      "metadata": {
        "id": "b19b0b4a"
      },
      "source": [
        "Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbcb585",
      "metadata": {
        "id": "3fbcb585"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    data = data_loader()\n",
        "    plot_raw_data(data)\n",
        "    train, test = data_allocation(data)\n",
        "    plot_train_test(train, test)\n",
        "    print(f\"Enter the Lag Value for the Neural Network to Work : {n}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf20f29",
      "metadata": {
        "id": "acf20f29"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190573d6",
      "metadata": {
        "id": "190573d6"
      },
      "outputs": [],
      "source": [
        "st1 = time.time()\n",
        "model, history, full_predictions = LSTM(train, n, number_nodes, learning_rate, epochs, batch_size)\n",
        "plot_predictions(train[n:], full_predictions, \"LSTM PREDICTIONS VS ACTUAL Values For TRAIN Data Set\")\n",
        "last_sequence = train[-n:].values.reshape((1, n, 1))\n",
        "predictions = []\n",
        "\n",
        "for i in range(days + 1):\n",
        "    next_prediction = model.predict(last_sequence).flatten()[0]\n",
        "    predictions.append(next_prediction)\n",
        "\n",
        "    if i < len(test):\n",
        "        actual_value = test.iloc[i]\n",
        "        new_row = np.append(last_sequence[:, 1:, :], np.array([[[actual_value]]]), axis=1)\n",
        "    else:\n",
        "        new_row = np.append(last_sequence[:, 1:, :], np.array([[[next_prediction]]]), axis=1)\n",
        "\n",
        "    last_sequence = new_row.reshape((1, n, 1))\n",
        "\n",
        "plot_predictions(test, predictions[:-1], \"LSTM Predictions VS Actual Values\")\n",
        "errors_data = Error_Evaluation(train, full_predictions, n)\n",
        "plot_prediction_errors(errors_data)\n",
        "\n",
        "print(f\"\\n\\n----------------------------- THE {days} PREDICTION VALUES FROM LSTM ---------------------------------------------------\\n\\n\")\n",
        "for i in range(days):\n",
        "    actual_value = test.iloc[i] if i < len(test) else \"No actual value (out of range)\"\n",
        "    print(f\"Day {i + 1} => ACTUAL VALUE : {actual_value} | PREDICTED VALUE : {predictions[i]}\\n\")\n",
        "\n",
        "print(\"\\n---------------------------- The LSTM Model Summary is : ----------------------------\\n\")\n",
        "print(model.summary())\n",
        "mse, rmse, mae = calculate_accuracy(test[:days], predictions[:days])\n",
        "plot_accuracy(mse, rmse, mae)\n",
        "\n",
        "print(\"\\n----------------------------- LSTM MODEL ACCURACY -----------------------------\\n\")\n",
        "print(f\"\\nMEAN SQUARED ERROR : {mse}\\nROOT MEAN SQUARED ERROR : {rmse}\\nMEAN ABSOLUTE ERROR : {mae}\\n\\n\")\n",
        "\n",
        "ord = Parameter_calculation(errors_data)\n",
        "Arima_Model, predictions_errors, full_predictions_errors = ARIMA_Model(errors_data, len(test), ord)\n",
        "\n",
        "print(f\"\\n\\n---------------------------- ARIMA MODEL {days} Predictions-------------------------\\n\\n\")\n",
        "for i, error in enumerate(predictions_errors):\n",
        "    print(f\"{i + 1} : {error}\\n\")\n",
        "\n",
        "print(\"\\n---------------------------- ARIMA MODEL Summary -------------------------\\n\")\n",
        "print(Arima_Model.summary())\n",
        "\n",
        "arima_mse, arima_rmse, arima_mae = calculate_accuracy(errors_data, full_predictions_errors)\n",
        "plot_arima_accuracy(arima_mse, arima_rmse, arima_mae)\n",
        "\n",
        "print(\"\\n\\n--------------------------- FINAL PREDICTIONS ---------------------------------\\n\\n\")\n",
        "final_predictions = Final_Predictions(predictions_errors, predictions)\n",
        "plot_final_predictions(test[:days], final_predictions[:days])\n",
        "\n",
        "for i in range(days):\n",
        "    actual_value = test.iloc[i] if i < len(test) else \"No actual value (out of range)\"\n",
        "    print(f\"Day {i + 1} => ACTUAL VALUE : {actual_value} | PREDICTED VALUE : {final_predictions[i]}\\n\")\n",
        "\n",
        "print(f\"\\n---------------- Difference Between the LSTM Predictions and Final Predictions of {days} days ----------------\\n\")\n",
        "for i in range(days):\n",
        "    actual_value = test.iloc[i] if i < len(test) else \"No actual value (out of range)\"\n",
        "    print(f\"\\n{i} DAY => ACTUAL VALUE : {actual_value} | LSTM PREDICTED VALUE : {predictions[i]} | FINAL PREDICTION(LSTM + ARIMA) : {final_predictions[i]}\\n\")\n",
        "\n",
        "print(f\"\\n\\n---------------- The FORECAST VALUE OF NEXT DATA POINT IS ------------------ \\n\\n\")\n",
        "print(predictions[days] + predictions_errors[days])\n",
        "\n",
        "end1 = time.time()\n",
        "print(f\"\\n\\nTime taken for model training and predictions: {end1 - st1:.2f} seconds\\n\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}